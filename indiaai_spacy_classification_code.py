# -*- coding: utf-8 -*-
"""IndiaAI_Spacy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ykSZzTlWpcHc0LTHavSEbTbASqVtlzzw
"""

# import torch

# # Check if MPS is available (for Apple Silicon)
# mps_available = torch.backends.mps.is_available()
# print("Is MPS available:", mps_available)

# # Check if CUDA is available (for NVIDIA GPUs, not relevant here)
# cuda_available = torch.cuda.is_available()
# print("Is CUDA available:", cuda_available)

# # Print device info
# if mps_available:
#     print("Using MPS (Apple Silicon) for GPU acceleration.")
# elif cuda_available:
#     print("Using CUDA for NVIDIA GPU.")
# else:
#     print("No GPU detected.")


import spacy
from spacy.training.example import Example
import pandas as pd

# Load train and test data
train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")

def prepare_data(df):
    spacy_data = []
    for _, row in df.iterrows():
        text = row["crimeaditionalinfo"]
        # Dictionary of categories as required by SpaCy for multi-label classification
        cats = {
            "CATEGORY_" + str(row["category"]): True,  # Prefix to avoid label conflicts
            "SUB_CATEGORY_" + str(row["sub_category"]): True
        }
        spacy_data.append((text, {"cats": cats}))
    return spacy_data

# Prepare training and test data
train_spacy_data = prepare_data(train_data)
test_spacy_data = prepare_data(test_data)

# Initialize a blank SpaCy model and add TextCategorizer with multilabel support
# nlp = spacy.blank("en")
nlp = spacy.load("en_core_web_trf")
textcat = nlp.add_pipe("textcat")

# Add labels for all categories and sub-categories
for _, annotations in train_spacy_data:
    for label in annotations["cats"]:
        textcat.add_label(label)

# Initialize optimizer
optimizer = nlp.initialize()

# Ensure SpaCy is set to use the GPU
# spacy.require_gpu()

## Training loop
n_epochs = 1

for epoch in range(n_epochs):
   print(f"Starting epoch {epoch + 1}")
   losses = {}

   for i, (text, annotations) in enumerate(train_spacy_data):
       if not isinstance(text, str):
           continue
       # Prepare the example for training
       doc = nlp.make_doc(text)
       example = Example.from_dict(doc, annotations)

       # Update the model
       nlp.update([example], sgd=optimizer, losses=losses)

       # Display the current loss every 100 examples
       if (i + 1) % 100 == 0:
           print(f"Processed {i + 1} examples, Current loss: {losses['textcat']:.4f}")

   # Print loss at the end of each epoch
   print(f"Loss at the end of epoch {epoch + 1}: {losses}")

# Assuming 'nlp' is your trained spaCy model
nlp.to_disk("nlp_model_2")

# nlp = spacy.load("nlp_model")

print(nlp.get_pipe("textcatl").labels)

## Evaluation
#correct = 0
#total = len(test_spacy_data)
#
#for text, annotations in test_spacy_data:
#    if not isinstance(text, str):
#        continue
#    doc = nlp(text)
#    cats_pred = doc.cats
#    cats_true = annotations["cats"]
#
#    # Initialize a flag for tracking if the prediction matches
#    match = True
#
#    # Check if predicted categories match the actual categories
#    for label in cats_true:
#        # Check if the label exists in predicted categories
#        if label in cats_pred:
#            # Compare predicted and true values
#            if (cats_pred[label] >= 0.99) != cats_true[label]:
#                match = False
#                break  # Exit loop if there's a mismatch
#        else:
#            print(f"Warning: Category '{label}' not found in predicted categories.")
#
#    # Increment correct count if match is True
#    if match:
#        correct += 1
#
#
#accuracy = correct / total
#print(f"Accuracy: {accuracy * 100:.2f}%")



# Step 3: Initialize counters for evaluation
correct_predictions = 0
total_predictions = len(test_spacy_data)

## Step 4: Run predictions and evaluate
#for text, annotations in test_spacy_data:
#    if not isinstance(text, str):
#        continue
#    doc = nlp(text)  # Process the text with the model
#    print('doc: ', doc)
#    cats_pred = doc.cats  # Get predicted categories
#    print('doc.cats: ', doc.cats)
#    cats_true = annotations["cats"]  # Get true categories
#    print('cats_true: ', cats_true)
#
#    # Initialize a flag for tracking if the prediction matches
#    match = True
#
#    # Check predictions for each category
#    for label in cats_true:
#        # Ensure the label exists in predicted categories
#        if label in cats_pred:
#            predicted = 1 if cats_pred[label] >= 0.5 else 0  # Binary threshold
#            true = cats_true[label]
#            
#            # Check if predicted matches true
#            if predicted == true:
#                correct_predictions += 1
#        else:
#            print(f"Warning: Category '{label}' not found in predicted categories.")
#
## Step 5: Calculate and print the matching percentage
#if total_predictions > 0:
#    matching_percentage = (correct_predictions / total_predictions) * 100
#else:
#    matching_percentage = 0
#
#print(f"Correct Predictions: {correct_predictions} out of {total_predictions}")
#print(f"Matching Percentage: {matching_percentage:.2f}%")


# Step 4: Run predictions and evaluate
for text, annotations in test_spacy_data:
    if not isinstance(text, str):
        correct_predictions += 1
        continue
    
    doc = nlp(text)  # Process the text with the model
    # print('doc: ', doc)
    cats_pred = doc.cats  # Get predicted categories
    # print('doc.cats: ', cats_pred)
    cats_true = annotations["cats"]  # Get true categories
    # print('cats_true: ', cats_true)

    # Find the category with the highest confidence score
    if cats_pred:  # Ensure there are predicted categories
        predicted_label = max(cats_pred, key=cats_pred.get)  # Get the category with the highest score
        predicted_score = cats_pred[predicted_label]  # Get the corresponding score
    else:
        predicted_label = None
        predicted_score = 0

    # Check if the predicted category is among the true categories
    match = False
    if predicted_label in cats_true:
        # Convert prediction to binary (1 for true, 0 for false) based on a threshold
        predicted_binary = 1 if predicted_score >= 0.5 else 0
        true_binary = cats_true[predicted_label]

        # Check if the predicted binary matches the true binary
        if predicted_binary == true_binary:
            match = True

    # Increment correct predictions if there's a match
    if match:
        correct_predictions += 1
    else:
        print('doc.cats: ', cats_pred)
        print('cats_true: ', cats_true)
        print(f"Prediction: '{predicted_label}' (Score: {predicted_score}) does not match true category. {cats_true}")

# Step 5: Calculate and print the matching percentage
if total_predictions > 0:
    matching_percentage = (correct_predictions / total_predictions) * 100
else:
    matching_percentage = 0

print(f"Correct Predictions: {correct_predictions} out of {total_predictions}")
print(f"Matching Percentage: {matching_percentage:.2f}%")
